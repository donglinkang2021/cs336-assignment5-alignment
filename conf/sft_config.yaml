
defaults:
  - val_datasets:
    - math500
    - competition_math_500
    - gsm8k
  - _self_

model:
  model_name_or_path: models/Qwen2.5-Math-1.5B
  dtype: bfloat16
  gradient_checkpointing: true
  attn_implementation: flash_attention_2

data:
  train_data_path: data/OMR12k-formated/train.jsonl
  num_train_examples: null
  prompt_name: r1_zero

training:
  output_dir: ckpt/sft_omr12k_2
  num_epochs: 1
  batch_size: 2
  gradient_accumulation_steps: 8
  learning_rate: 5e-6
  weight_decay: 0.01
  max_grad_norm: 1.0
  warmup_ratio: 0.1
  lr_scheduler_type: cosine
  seed: 42

evaluation:
  eval_steps: 50
  save_steps: 100
  max_eval_examples: 100
  eval_n_times: 1
  use_vllm_eval: true
  generation_temperature: 0.6
  generation_top_p: 0.95
  generation_max_tokens: 32768

logging:
  use_wandb: true
  wandb_project: cs336-assignment5-alignment
  wandb_run_name: sft_omr12k

hydra:
  run:
    dir: ${training.output_dir}/runs/${now:%Y-%m-%d}_${now:%H-%M-%S}
  sweep:
    dir: ${training.output_dir}/multiruns/${now:%Y-%m-%d}_${now:%H-%M-%S}
    subdir: ${hydra.job.num}
  job_logging:
    handlers:
      file:
        filename: ${hydra.runtime.output_dir}/${hydra.job.name}.log
