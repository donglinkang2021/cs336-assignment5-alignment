## 2.2 GSM8K

**Prompting setup.** To evaluate zero-shot performance on GSM8K, we’ll simply load the examples and prompt the language model to answer the question with the following input:

```
{question}
Answer:
```

In the prompt above, `question` refers to the GSM8K question (e.g., *Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?*).

**Evaluation metric.** To evaluate the model’s outputs, we’ll parse its generations by taking the final number in the predicted output as its predicted answer. For example, the generated output *She sold 15 clips.* would be parsed to `15`. This is compared against the gold answer (`72`) to evaluate the model’s performance.

**Generation hyperparameters.** When generating responses, we’ll use greedy decoding (i.e., temperature of 0.0, with top-p 1.0).

### Problem (gsm8k_baseline): 4 points

(a) Write a function to parse generated language model outputs into a single numeric prediction. If a model response cannot be parsed, return `None`. To test your function, implement the adapter `[run_parse_gsm8k_response]` and make sure it passes `uv run pytest -k test_parse_gsm8k_response`.

**Deliverable:** A function to parse generated predictions on GSM8K into a single numeric answer.

(b) Write a script to evaluate Llama 3.1 8B zero-shot performance on GSM8K. This script should (1) load the GSM8K examples, (2) format them as string prompts to the language model, and (3) generate outputs for each example. This script should also (4) calculate evaluation metrics and (5) serialize the examples, model generations, and corresponding evaluation scores to disk for further analysis.

**Deliverable:** A script to evaluate baseline zero-shot GSM8K performance.

(c) Run your evaluation script on Llama 3.1 8B. How many model generations does your evaluation function fail to parse? If non-zero, what do these examples look like?

**Deliverable:** Number of model generations that failed parsing. If non-zero, a few examples of generations that your function wasn’t able to parse.

(d) How long does it take the model to generate responses to each of the GSM8K examples? Estimate the throughput in examples/second.

**Deliverable:** Estimate of GSM8K examples/second throughput.

(e) How well does the Llama 3.1 8B zero-shot baseline perform on GSM8K?

**Deliverable:** 1-2 sentences with evaluation metrics.

(f) Sample 10 random incorrectly-predicted examples from the evaluation dataset. Looking through the examples, what sort of errors does the language model make?

**Deliverable:** A 2-4 sentence error analysis of model predictions, including examples and/or model responses as necessary.
