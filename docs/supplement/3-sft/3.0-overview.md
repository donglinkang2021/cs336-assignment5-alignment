# 3. Instruction Fine-Tuning

From inspecting the outputs of the zero-shot baseline model, you may have noticed that it can often be difficult to get language models to reliably follow instructions via prompting alone. In this part of the assignment, weâ€™ll explicitly fine-tune `Llama 3.1` to follow instructions. Training a language model on data with paired *(prompt, response)* demonstrations is often called *instruction fine-tuning* (or *supervised fine-tuning*; SFT).
