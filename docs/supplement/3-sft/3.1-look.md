## 3.1 Looking at instruction tuning data

To instruction fine-tune our language models, we’ll use a mix of data from the [UltraChat-200K dataset](https://huggingface.co/datasets/HuggingFaceH4/ultrachat_200k) and the [SafetyTunedLlamas dataset](https://github.com/vinid/safety-tuned-llamas). This data has been processed into a single-turn format (i.e., a single prompt and a single response). We’ve placed it on the Together cluster at:

*   [`/data/a5-alignment/safety_augmented_ultrachat_200k_single_turn/train.jsonl.gz`](https://nlp.stanford.edu/data/nfliu/cs336-spring-2024/assignment5/safety_augmented_ultrachat_200k_single_turn/train.jsonl.gz)
*   [`/data/a5-alignment/safety_augmented_ultrachat_200k_single_turn/test.jsonl.gz`](https://nlp.stanford.edu/data/nfliu/cs336-spring-2024/assignment5/safety_augmented_ultrachat_200k_single_turn/test.jsonl.gz)

Let’s look through the provided instruction fine-tuning data and get a sense of it.

**Problem (look\_at\_sft): 4 points**

Look through ten random examples in the provided instruction tuning training dataset. What sort of traditional NLP tasks are represented in this sample (e.g., question answering, sentiment analysis, etc.)? Comment on the quality of the sampled examples (both the prompt and the corresponding instruction).

**Deliverable:** 2-4 sentences with a description of what sorts of tasks are implicitly included in the instruction tuning dataset, as well commentary about the data quality. Use concrete examples whenever possible.
