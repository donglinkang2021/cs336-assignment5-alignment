## 4.3 AlpacaEval

**Problem (alpaca_eval_sft): 4 points**

1.  Write a script to collect the predictions of your fine-tuned model on AlpacaEval. How long does it take the model to generate responses to each of the AlpacaEval examples? Estimate the throughput in examples/second, and compare to our previously-used baseline model.

    > **Deliverable:** 1-2 sentences with an estimate of AlpacaEval examples/second throughput and a comparison to the baseline model.

2.  To measure our model’s performance on AlpacaEval, we’ll use Llama 3.3 70B Instruct as the annotator and compare our outputs against GPT-4 Turbo. To compute the winrate, run the following command (requires two GPUs, each with more than 80GB of memory):

    ```bash
    uv run alpaca_eval --model_outputs <path_to_model_predictions.json> \
    --annotators_config 'scripts/alpaca_eval_vllm_llama3_3_70b_fn' \
    --base-dir '.'
    ```

    This command will load our model outputs and run Llama 3.3 70B locally to get its preference judgments and compute the corresponding winrate. What is the winrate and length-controlled winrate of your instruction-tuned model when compared against GPT-4 Turbo and using Llama 3.3 70B Instruct as the annotator? How does this winrate compare to our zero-shot baseline?

    > **Deliverable:** 1-3 sentences with the winrate and length-controlled winrate, as well a comparison against the zero-shot baseline.

3.  Sample 10 random examples where your fine-tuned model’s response is dispreferred versus GPT-4 Turbo. You should be able to see the AlpacaEval annotations at `scripts/alpaca_eval_vllm_llama3_3_70b_fn/annotations_seed0_configs.json`, and the entries where "preference" is equal to 1.0 are the examples where the evaluator judged the GPT-4 Turbo response to be better. Looking through the examples, why do you think your fine-tuned model is dispreferred? Are there any cases where you disagree with the automatic evaluator?

    > **Deliverable:** A 2-4 sentence error analysis of model predictions, including examples and/or model responses as necessary.
