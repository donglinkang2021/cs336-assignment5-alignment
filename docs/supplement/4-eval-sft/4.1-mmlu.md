## 4.1 MMLU

**Problem (mmlu_sft): 4 points**

1.  Write a script to evaluate your instruction-tuned model on MMLU, making sure to format the inputs in the same instruction tuning prompt format used for training. Run your evaluation script and measure the amount of time it takes for the model to generate responses to each of the MMLU examples. Estimate the throughput in examples/second. How does this compare to our zero-shot baseline?

    > **Deliverable:** 1-2 sentences with an estimate of MMLU examples/second throughput and a comparison to the zero-shot baseline.

2.  How well does the instruction-tuned model perform on MMLU? How does this compare to our zero-shot baseline?

    > **Deliverable:** 1-2 sentences with evaluation metrics and a comparison to the zero-shot baseline.

3.  Sample 10 random incorrectly-predicted examples from the evaluation dataset. Looking through the examples, what sort of errors does the language model make? Qualitatively, how do the outputs of the fine-tuned model differ from the outputs of the zero-shot baseline?

    > **Deliverable:** A 2-4 sentence error analysis of model predictions, including examples and/or model responses as necessary.
